<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Project 2 -- Stats/Chats | CSCI 121 Computer Science I</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Complete and submit by 3&#x2F;30 at 1:00pm For this project, you will be working with lists and dictionaries to perform some form of data analysis. Specifically, you will be generating text based on a">
<meta property="og:type" content="article">
<meta property="og:title" content="Project 2 -- Stats&#x2F;Chats">
<meta property="og:url" content="https://nchanath.github.io/121-S23/2023/01/12/proj2/index.html">
<meta property="og:site_name" content="CSCI 121 Computer Science I">
<meta property="og:description" content="Complete and submit by 3&#x2F;30 at 1:00pm For this project, you will be working with lists and dictionaries to perform some form of data analysis. Specifically, you will be generating text based on a">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-01-13T07:05:50.000Z">
<meta property="article:modified_time" content="2023-01-13T07:16:28.318Z">
<meta property="article:author" content="Chanathip Namprempre">
<meta property="article:tag" content="Homework">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@ajmeaw">
  
    <link rel="alternate" href="/121-S23/atom.xml" title="CSCI 121 Computer Science I" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/121-S23/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/121-S23/css/style.css">

  
    
<link rel="stylesheet" href="/121-S23/fancybox/jquery.fancybox.min.css">

  
  <script type="text/javascript" async
          src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script>
    MathJax.Ajax.config.path["Contrib"] = "https://cdn.mathjax.org/mathjax/contrib";
    MathJax.Ajax.config.path["font"] = "https://cdn.mathjax.org/mathjax/font";
  </script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/121-S23/" id="logo">CSCI 121 Computer Science I</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/121-S23/tags/Announcements">Announcements</a>
        
          <a class="main-nav-link" href="/121-S23/syllabus">Syllabus</a>
        
          <a class="main-nav-link" href="/121-S23/lecturenotes">Lecture Notes</a>
        
          <a class="main-nav-link" href="/121-S23/tags/Handouts">Handouts</a>
        
          <a class="main-nav-link" href="/121-S23/tags/Homework">Homework</a>
        
          <a class="main-nav-link" href="/121-S23/resources">Resources</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/121-S23/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://nchanath.github.io/121-S23"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-proj2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/121-S23/2023/01/12/proj2/" class="article-date">
  <time class="dt-published" datetime="2023-01-13T07:05:50.000Z" itemprop="datePublished">2023-01-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Project 2 -- Stats/Chats
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><strong>Complete and submit by 3&#x2F;30 at 1:00pm</strong></p>
<p>For this project, you will be working with lists and dictionaries to perform some form of data analysis. Specifically, you will be generating text based on analysis of other texts. </p>
<p>This project has two parts.  The first part is a text analyzer that reports statistics about word use in the text it processes. The second part builds from the same idea, but pays attention instead to the <em>bi-grams</em> and <em>tri-grams</em> (runs of 2 or 3 words) of the text it analyzes, training a random process.  That process generates a random text that mimics the writing of the text by which it was trained.</p>
<p>The first part will feel quite a bit like you are solving several lab homework exercises. You should work to get Part 1 working quickly.  The set-up of the first part is to help you see how a larger Python script can can be structured. It will teach you how to decompose a coding project so as to allow for incremental progress in its completion and also to enable easy testing of its components.</p>
<p>Having completed Part 1, you’ll then want work to quickly learn the ideas necessary for completing Part 2. You’ll probably also want to break that coding up into several functions like we do for Part 1, but we let you use your own judgement to do that work.</p>
<p>• Download the <a href="stats-chats.zip"><strong>project folder</strong></a> for this work.</p>
<h2 id="On-text-analysis"><a href="#On-text-analysis" class="headerlink" title="On text analysis"></a>On text analysis</h2><p>There is a growing area of the study called <em>digital humanities</em> that treats human-written texts as <em>data</em>, making them subject to the same kinds of analysis that scientists and social scientists my use to reason about their objects of study. By treating a text this way a scholar may get insights into an author’s use of language. What is the structure of their prose? What word choices do they tend to make? Do they have a signature style that can be quantified in some way? Such analyses might, for example, help us identify an author of an anonymous text, or be used as evidence to support or reject hypothesized authors.</p>
<p>The first cut at such analyses looks at word frequencies. Suppose, in a 500 page text, the author used 10000 words only once. What does that say about their writing? Does that say anything about their prose? Maybe they use verbs in a passive versus and active tense.  Do their sentences tend to be long or short?  Etc. Alternatively: how many times does a character’s name appear in a certain novel?</p>
<p>The algorithms and data structures that support these kinds of analyses, it turns out, are fairly foundational and can be applied in many settings. The same techniques you might use to analyze a text, can also be used to study genetic sequences, or protein structure, and maybe even general data that makes up our files’ and programs’ sequences of bits.</p>
<p>Related to this is the question of information content, the essential make-up of text, digitally speaking. Can the document be compressed so that it uses fewer bits? Can we summarize some of its content? Can we make its ideas searchable? Can we relate it to other documents in some way?</p>
<h2 id="On-text-synthesis"><a href="#On-text-synthesis" class="headerlink" title="On text synthesis"></a>On text synthesis</h2><p>Also related to these notions of how we characterize a text digitally is a question of <em>text generation</em>. Can we use our techniques to generate novel, meaningful sequences of words? As we hear in the news, there are <em>bots</em> that post information on sites, send spam emails, and in some very near future will interact with us in text or in speech in novel ways.</p>
<p>We are in the midst of a technical revolution in this regard: deep learning and statistical techniques are able to represent parsable sentence structure in some remarkable ways and can string words together <a target="_blank" rel="noopener" href="https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker">so as to have seeming meaning and content.</a> Nevertheless, there is much work to be done, and every development highlights the difficulty of natural language processing and synthesis, and the huge complexity that must clearly be involved in human thought and communication.</p>
<p>For this project we build a very simple model for synthesizing sequences of words that mimiic human-written texts, albeit in a very limited way.  We build a <em>stochastic process</em> by analyzing the frequency of the third word of every three-word sequence in a text. The idea here is that, when we are reading a text (say, the words you are reading <em>right now</em>) our minds build expectations for the next word we read based on the last few words we’ve just read.</p>
<p>If you read “<em>The dog…</em>“, say, you might not be surprised if the next word is “<em>barked</em>“, or “<em>sat</em>“, or “<em>slept</em>“, and maybe even “<em>park</em>“ or “<em>house</em>“. You might not expect “<em>purred</em>“, or “<em>philosophized</em>“, or “<em>rented</em>“, and probably not “<em>candelabra</em>“ or “<em>eight</em>“.  And, maybe having then read “<em>The dog barked</em>“, you’d be surprised to see “<em>sat</em>“ next and not be surprised to see “<em>loudly</em>“ next.</p>
<p>Imagine processing the text of a novel whose main character has a faithful dog companion in a few key moments of its story.  The two-word sequence (or <em>bi-gram</em>) “<em>the dog</em>“ might occur 12 times, and have “<em>slept</em>“ follow 3 of those times, have “<em>barked</em>“ follow 5 times, have “<em>sat</em>“ follow twice, and “<em>park</em>“ follow twice.  And maybe “<em>dog barked</em>“ would have “<em>at</em>“ happen several times (even more than 6, if “<em>his dog barked</em>“ was also a common triple), but also “<em>loudly</em>“ twice, and so on.</p>
<p>Using the data structures we just learned, we could build a dictionary full of a text’s bi-grams. Each entry in the dictionary could have the list of following words and their frequencies. The dictionary would have these contents represented as below</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123; # dictionary of bi-grams, along with their following words</span><br><span class="line">  ...</span><br><span class="line">  &quot;the dog&quot;:[[&quot;slept&quot;, 3], [&quot;barked&quot;,5], [&quot;sat&quot;,2], [&quot;park&quot;,2]],</span><br><span class="line">  ...</span><br><span class="line">  &quot;dog barked&quot;:[[&quot;at&quot;,...],</span><br><span class="line">  ...</span><br><span class="line">  &quot;his dog&quot;:[[&quot;barked&quot;,...]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In the above, we’ve chosen to represent the occurrences of words that follow bi-grams as a dictionary whose keys are strings. Each string contains two words separated by a space. Each of these bi-grams has an associated value in the dictionary. It is the list of words that follow that bi-gram in the text, paired with the number of times that word followed that bi-gram.</p>
<p>We can turn this analysis around to generate random text.  Suppose we decided to, while writing a novel, start with the words “<em>The dog</em>“, we could then chooose where to go next in our writing totally at random. We toss a 12-sided die, choosing to type “<em>slept</em>“ if 1, 2, or 3 comes up, “<em>barked</em>“ if 4 through 8 comes up, “<em>sat</em>“ if 9 or 10, and “<em>park</em>“ if we roll an 11 or 12.  And say we rolled a 10.  We type “<em>sat</em>“ and then play the same random game to maybe choose between “<em>down</em>“ or “<em>between</em>“ or “<em>on</em>“, etc. Continuing this way, maybe we write a random novel.</p>
<h1 id="Text-analysis-with-stats-py"><a href="#Text-analysis-with-stats-py" class="headerlink" title="Text analysis with stats.py"></a>Text analysis with <code>stats.py</code></h1><p>As a warm up to analyzing the bi-grams of a text, we start by just analyzing the use of individual words. We’re going to write code that reads the words of a text, stored in a text file, and counts how many times each word appears in that text.</p>
<p>In the downloaded project folder you’ll find the starting code for this part of the assignment, the file <code>stats.py</code>. It contains a script that gets the name of the text’s file, processes the file, and then reports the frequency of occurrence of words appearing in that text. Once you’ve written everything, your program should have the kind of interaction shown below:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ python3 stats.py</span><br><span class="line">READING text from STDIN. Hit ctrl-d when done entering text.</span><br><span class="line">Fair Reed</span><br><span class="line">All hail, Alma Mater, new born of the West</span><br><span class="line">Where the mighty Columbia flows,</span><br><span class="line">Thou fortunate heir of the pioneers&#x27; quest,</span><br><span class="line">All hail to the griffin and rose.</span><br><span class="line">Thou wilt cherish thine own through woe and through weal,</span><br><span class="line">Thou wilt throw on the pathway a light,</span><br><span class="line">Never dimming the truth thru a partisan&#x27;s zeal,</span><br><span class="line">Never doubting the triumph of right.</span><br><span class="line">DONE.</span><br><span class="line">HERE are the word statistics of that text:</span><br><span class="line"></span><br><span class="line">That text was 62 words in length.</span><br><span class="line"></span><br><span class="line">There are 45 distinct words used in that text.</span><br><span class="line"></span><br><span class="line">The top 10 ranked words (with their frequencies) are:</span><br><span class="line">1. the:7, 2. thou:3, 3. of:3, 4. never:2, 5. a:2, 6. through:2, 7. w</span><br><span class="line">ilt:2, 8. and:2, 9. hail:2, 10. all:2</span><br><span class="line"></span><br><span class="line">Among its 45 words, 35 of them appear exactly once.</span><br></pre></td></tr></table></figure>

<p>You should know that, in the above, the lines from “<code>Fair Reed</code>“ down to the line above “<code>DONE.</code>“ were entered by the user into the console.  After they hit the <code>[RETURN]</code> key, they they hit <code>[CONTROL-d]</code> to signal the end of text (this is the console’s “end of file” keystroke), and then the program produced the subsequent output.</p>
<p>Below is another run, but using a special feature of the console called <em>input redirection</em>. The <code>&lt;</code> tells the console to feed in the contents of the file <code>jabberwocky.txt</code> as if they are being typed in directly by the user. Here is that run:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ python3 stats.py &lt; jabberwocky.txt</span><br><span class="line">READING text from STDIN. Hit ctrl-d when done entering text.</span><br><span class="line">DONE.</span><br><span class="line">HERE are the word statistics of that text:</span><br><span class="line"></span><br><span class="line">That text was 166 words in length.</span><br><span class="line"></span><br><span class="line">There are 90 distinct words used in that text.</span><br><span class="line"></span><br><span class="line">The top 10 ranked words (with their frequencies) are:</span><br><span class="line">1. the:19, 2. and:14, 3. he:7, 4. in:6, 5. through:3, 6. my:3, 7. ja</span><br><span class="line">bberwock:3, 8. went:2, 9. two:2, 10. one:2</span><br><span class="line"></span><br><span class="line">Among its 90 words, 55 of them appear exactly once.</span><br></pre></td></tr></table></figure>

<p>This text file contains Lewis Carroll’s somewhat gibberish-y poem <em>Jabberwocky</em> and has lots of used-once words. There are several used twice, and the code just happens to report a few of these, including the word “<em>went</em>.”</p>
<p>As you use the code and make it work, you’ll notice that the code considers “stop punctuation”— the marks <code>.</code>, <code>!</code>, and <code>?</code> specially.  This will be useful for text synthesis, later. It ignores other punctiation marks except for the contraction mark <code>&#39;</code>, which it considers a letter of a word. It treats all letters as their lowercase.  It currently fails to properly process accented letters, ignoring them and only paying attention to <code>a</code> through <code>z</code>, <code>A</code> through <code>Z</code>.</p>
<p>For shorter entries (fewer than 10 words), it only reports a most frequent word. For medium (fewer than 100), it only reports the top 10. For longer texts, it reports the top 100. Here is an example of it processing the full text of an English translation of Gabriel García Márquez’s <em>One Hundred Years of Solitude</em>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">$ python3 stats.py &lt; hundred_years.txt</span><br><span class="line">READING text from STDIN. Hit ctrl-d when done entering text.</span><br><span class="line">DONE.</span><br><span class="line">HERE are the word statistics of that text:</span><br><span class="line"></span><br><span class="line">That text was 146763 words in length.</span><br><span class="line"></span><br><span class="line">There are 10659 distinct words used in that text.</span><br><span class="line"></span><br><span class="line">The top 100 ranked words (with their frequencies) are:</span><br><span class="line">1. the:10927, 2. of:5255, 3. and:4202, 4. to:3685, 5. a:3188, 6. tha</span><br><span class="line">t:3171, 7. in:3040, 8. he:2728, 9. was:2370, 10. had:2175, 11. her:2</span><br><span class="line">046, 12. with:2018, 13. she:1984, 14. his:1886, 15. on:1158, 16. him</span><br><span class="line">:1127, 17. not:1090, 18. it:1077, 19. for:1050, 20. they:963, 21. as</span><br><span class="line">:877, 22. one:812, 23. by:806, 24. would:792, 25. at:779, 26. aureli</span><br><span class="line">ano:766, 27. but:746, 28. who:674, 29. when:670, 30. were:666, 31. f</span><br><span class="line">rom:597, 32. so:564, 33. time:546, 34. an:503, 35. them:477, 36. did</span><br><span class="line">:471, 37. arcadio:466, 38. ursula:459, 39. jose:439, 40. up:436, 41.</span><br><span class="line">which:423, 42. house:418, 43. been:414, 44. out:399, 45. their:386,</span><br><span class="line">46. only:372, 47. year s:371, 48. be:370, 49. because:356, 50. all:3</span><br><span class="line">49, 51. into:342, 52. buendia:333, 53. could:330, 54. about:322, 55.</span><br><span class="line"> no:320, 56. have:317, 57. colonel:308, 58. more:301, 59. said:298,</span><br><span class="line">60. amaranta:289, 61. segundo:284, 62. then:265, 63. where:264, 64.</span><br><span class="line">even:263, 65. like:252, 66. solitude:250, 67. without:249, 68. hundr</span><br><span class="line">ed:245, 69. there:235, 70. put:235, 71. went:228, 72. first:228, 73.</span><br><span class="line"> if:224, 74. gabriel:216, 75. made:209, 76. room:208, 77. over:207,</span><br><span class="line">78. garcia:206, 79. any:205, 80. until:204, 81. after:203, 82. you:2</span><br><span class="line">03, 83. x:202, 84. took:201, 85. marques:201, 86. before:194, 87. th</span><br><span class="line">an:192, 88. through:191, 89. what:188, 90. fernanda:187, 91. two:187</span><br><span class="line">, 92. same:186, 93. other:186, 94. macondo:175, 95. night:172, 96. b</span><br><span class="line">ack:172, 97. man:172, 98. its:170, 99. left:169, 100. day:166</span><br><span class="line"></span><br><span class="line">Among its 10659 words, 4486 of them appear exactly once.</span><br></pre></td></tr></table></figure>

<h2 id="Coding-stats-py"><a href="#Coding-stats-py" class="headerlink" title="Coding stats.py"></a>Coding <code>stats.py</code></h2><p>The starter code provided has a fully written script, but its code relies on several helper functions that have not been written.  Below I list each of these functions, giving descriptions of how each should behave. Work to complete each of these to get Part 1 working fully.</p>
<p>Many of these functions operate on either a list of strings that are words from the entered text, or else a dictionary that summarizes the number of occurrences of each word in the text. The dictionary stores the word frequencies of the text. We compute a list of the most frequently used words in the text, ordered from the most frequent to the least frequent, among those words.</p>
<p>To compute these summaries of the text, there is some pre-written code that simplifies the text that was entered. Words are made lowercase, some punctuation is removed, and most non-alphabetic characters are ignored. The exception is apostrophes, which are kept for contractions like <code>&quot;isn&#39;t&quot;</code> or <code>&quot;it&#39;s&quot;</code>. The other exception is punctuation that normally ends English sentences, namely <code>&quot;.&quot;</code>, <code>&quot;!&quot;</code>, and <code>&quot;?&quot;</code>. We refer to these as <em>stoppers</em> and a lot of the functions below sometimes ask you to treat these strings as part of a word list, but then treat them specially.</p>
<p>For example, consider this interaction:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ python3 stats.py</span><br><span class="line">READING text from STDIN. Hit ctrl-d when done entering text.</span><br><span class="line">Well, hello there, Jim. *87&amp;#@* Hello!</span><br><span class="line">DONE.</span><br></pre></td></tr></table></figure>
<p>Processing that single line of text, the code creates the word list:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&quot;well&quot;, &quot;hello&quot;, &quot;there&quot;, &quot;jim&quot;, &quot;.&quot;, &quot;hello&quot;, &quot;!&quot;]</span><br></pre></td></tr></table></figure>
<p>The text is simplified to a list of lowercase words and the stopper punctuation marks. The word frequency summary of this text will be the dictionary:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;well&#x27;:1, &#x27;hello&#x27;:2, &#x27;there&#x27;:1, &#x27;jim&#x27;:1&#125;</span><br></pre></td></tr></table></figure>
<p>Finally, if we were to list the two most frequently occurring words in this text, ordered from most- to least-frequent, that could be the list</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;hello&#x27;, &#x27;there&#x27;]</span><br></pre></td></tr></table></figure>
<p>But because two other words have equal frequency to <code>&#39;there&#39;</code>, these two other lists would be equally valid</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;hello&#x27;, &#x27;well&#x27;]</span><br><span class="line">[&#x27;hello&#x27;, &#x27;jim&#x27;]</span><br></pre></td></tr></table></figure>
<p>The order is arbitrary, and depends on how the analysis happens to order words that occur the same number of times.</p>
<p>With this information in mind, below we list each of those functions you need to write to complete this part of the assignment.</p>
<h2 id="Write-wordFrequencies"><a href="#Write-wordFrequencies" class="headerlink" title="Write wordFrequencies"></a>Write <code>wordFrequencies</code></h2><p>Write a function <code>def wordFrequencies(wordList)</code> that takes a list of strings. These strings are all the words in the text, along with the stopper punctuation marks. The function should build and return the word frequencies dictionary summarizing the occurrences of words in the text.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; wf = wordFrequencies([&quot;hello&quot;, &quot;there&quot;, &quot;.&quot;, &quot;hello&quot;, &quot;!&quot;])</span><br><span class="line">&gt;&gt;&gt; wf</span><br><span class="line">&#123;&#x27;hello&#x27;:2, &#x27;there&#x27;:1&#125;</span><br></pre></td></tr></table></figure>

<p>The list of punctuation marks considered to end sentences is given by the script variable <code>STOPPERS</code> and defined at the very top of the <code>stats.py</code> script. These strings should not be counted and should not appear in the dictionary.</p>
<h2 id="Write-wordCount"><a href="#Write-wordCount" class="headerlink" title="Write wordCount"></a>Write <code>wordCount</code></h2><p>Write a function <code>def wordCount</code> that takes a word frequencies dictionary <code>freqs</code> as its only parameter. It should return <em>a pair</em> of integer values.  The first component of the pair should be the size of the whole text in number of words. The second component of the pair should be the number of <em>distinct</em> words used in the text. The first is often called the <em>word count</em> of the text. The second is often called the <em>vocabulary size</em> of the text.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; wf = wordFrequencies([&quot;hello&quot;, &quot;there&quot;, &quot;.&quot;, &quot;hello&quot;, &quot;!&quot;])</span><br><span class="line">&gt;&gt;&gt; count,vocabSize = wordCount(wf)</span><br><span class="line">&gt;&gt;&gt; print(count,vocabSize,sep=&quot;,&quot;)</span><br><span class="line">3,2</span><br></pre></td></tr></table></figure>

<p>This, I believe, is the first time in this semester’s material where we have introduced a Python pair.  Pairs are an easy concept to understand. They are like a list, except their components cannot be modified. For example:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; my_pair = (3,7)</span><br><span class="line">&gt;&gt;&gt; my_pair[0]</span><br><span class="line">3</span><br><span class="line">&gt;&gt;&gt; my_pair[1]</span><br><span class="line">7</span><br><span class="line">&gt;&gt;&gt; len(my_pair)</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; my_pair[0] = 4</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">TypeError: &#x27;tuple&#x27; object does not support item assignment</span><br></pre></td></tr></table></figure>

<p>Python has a very convenient syntax for extracting the components of a pair. Instead of writing code like</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; my_pair = (3,7)</span><br><span class="line">&gt;&gt;&gt; first = my_pair[0]</span><br><span class="line">&gt;&gt;&gt; second = my_pair[1]</span><br><span class="line">&gt;&gt;&gt; print(first, second)</span><br><span class="line">3 7</span><br></pre></td></tr></table></figure>
<p>you can instead succinctly write</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; my_pair = (3,7)</span><br><span class="line">&gt;&gt;&gt; first, second = my_pair</span><br><span class="line">&gt;&gt;&gt; print(first, second)</span><br><span class="line">3 7</span><br></pre></td></tr></table></figure>

<p>This is a <em>mulitple assignment</em> or <em>multi-assignment</em> statement, and we are simultaneously assigning values to both <code>first</code> and <code>second</code> by extracting the information held in the pair <code>my_pair</code>.</p>
<p>Your <code>wordCount</code> function should return a pair.</p>
<h2 id="Write-topWordExcept"><a href="#Write-topWordExcept" class="headerlink" title="Write topWordExcept"></a>Write <code>topWordExcept</code></h2><p>Write a function <code>def topWordExcept(freqs,excluded)</code>. This takes a word frequencies dictionary <code>freqs</code> and a list of strings <code>excluded</code>.  The function should return a string that is the most frequently occurring word, but excluding the words that are in the list <code>excluded</code>.  (This code can be used to write the function <code>topWordsByFrequency</code> described just below.) If there are no words other than the ones in the excluded list, the function should return <code>None</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; wf = wordFrequencies([&quot;hello&quot;, &quot;there&quot;, &quot;.&quot;, &quot;hello&quot;, &quot;!&quot;])</span><br><span class="line">&gt;&gt;&gt; topWordExcept(wf,[])</span><br><span class="line">&#x27;hello&#x27;</span><br><span class="line">&gt;&gt;&gt; topWordExcept(wf,[&#x27;hello&#x27;])</span><br><span class="line">&#x27;there&#x27;</span><br><span class="line">&gt;&gt;&gt; print(topWordExcept(wf,[&#x27;hello&#x27;,&#x27;there&#x27;]))</span><br><span class="line">None</span><br></pre></td></tr></table></figure>

<h2 id="Write-topWordsByFrequency"><a href="#Write-topWordsByFrequency" class="headerlink" title="Write topWordsByFrequency"></a>Write <code>topWordsByFrequency</code></h2><p>Write a function <code>def topWordsByFrequency(freqs,howMany)</code> that takes a word frequencies dictionary <code>freqs</code> and an integer <code>howMany</code>. It should return a list of the most-frequent words in the text, according to the summary in <code>freqs</code>. The size of the list requested is given by <code>howMany</code>, and that parameter is assumed to be a non-negative integer.</p>
<p>Furthermore, the list returned should be organized so that the string at location 0 is a word that occurs the most, with the subsequent items in the list ordered by decreasing frequency.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; wf = wordFrequencies([&quot;hello&quot;, &quot;there&quot;, &quot;.&quot;, &quot;hello&quot;, &quot;!&quot;])</span><br><span class="line">&gt;&gt;&gt; topWordsByFrequeny(wf,1)</span><br><span class="line">[&#x27;hello&#x27;]</span><br><span class="line">&gt;&gt;&gt; topWordsByFrequency(wf,2)</span><br><span class="line">[&#x27;hello&#x27;, &#x27;there&#x27;]</span><br><span class="line">&gt;&gt;&gt; topWordsByFrequency(wf,0)</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>
<p>Note that there might be ties in word frequencies. Consider this use:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; wf = wordFrequencies([&quot;hello&quot;, &quot;there&quot;, &quot;goodbye&quot;, &quot;abe&quot;])</span><br><span class="line">&gt;&gt;&gt; twbf = topWordsByFrequency(wf,2)</span><br></pre></td></tr></table></figure>

<p>In the above, <code>twbf</code> could contain <code>hello</code> and <code>there</code>, or <code>hello</code> and <code>abe</code>, or <code>goodbye</code> and <code>there</code>, etc. Any two of those four words are the top two most-frequently occurring words.</p>
<h2 id="Write-rankedWordReport"><a href="#Write-rankedWordReport" class="headerlink" title="Write rankedWordReport"></a>Write <code>rankedWordReport</code></h2><p>In the reporting of the most frequently occurring words by <code>stats.py</code>, we rank the words, say, from 1 to 100 (if the text is long enough).  We use a function <code>rankedWordReport</code> to format that report.</p>
<p>Write the function <code>def rankedWordReport(ranking,topWordsList,freqs)</code>.  The first parameter <code>ranking</code> is a positive integer giving the rank of the word to report, The second parameter <code>topWordsList</code> is the most frequent words, a list of strings starting with the top ranked word, ordered by decreasing frequency. The third parameter <code>freqs</code> is the word frequencies dictionary. The function should return a string like below</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;1. the:1234&quot;</span><br></pre></td></tr></table></figure>

<p>The format of the string should be the ranking, followed by a period, followed by a space, followed by the word, followed by a colon character, followed by the number of occurrences of that word.  In that example, we see that the word “<em>the</em>“ occurred 1234 times.  This means that <code>topWordsList[0]</code> is “<em>the</em>“ and that <code>freqs[&quot;the&quot;]</code> equals <code>1234</code>.</p>
<h2 id="Write-numWordsWithFrequency"><a href="#Write-numWordsWithFrequency" class="headerlink" title="Write numWordsWithFrequency"></a>Write <code>numWordsWithFrequency</code></h2><p>Write a function <code>def numWordsWithFrequency(freqDict,freq)</code> that takes a word frequencies dictionary <code>freqDict</code> and a positive integer <code>freq</code>. It should give a count of the nummber of words in <code>freqDict</code> whose occurrence count equals <code>freq</code>. For example a call with <code>freq</code> of <code>1</code> would tell you how many words are used only once in the text.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; wf = &#123;&#x27;well&#x27;:1, &#x27;hello&#x27;:2, &#x27;there&#x27;: 1, &#x27;jim&#x27;:1&#125;</span><br><span class="line">&gt;&gt;&gt; numberWordsWithFrequency(wf,1)</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<h1 id="Text-synthesis-with-chats-py"><a href="#Text-synthesis-with-chats-py" class="headerlink" title="Text synthesis with chats.py"></a>Text synthesis with <code>chats.py</code></h1><p>The coding work described for <code>stats.py</code> pays attention to single word statistics in a text. Here, we instead consider runs of words in texts.  We process a text and pay attention to its <em>bigrams</em>, each consecutive pair of words in the text, and also its <em>trigrams</em>, each consecutive triple of words in the text.</p>
<p>Consider this excerpt from the <em>Odyssey</em>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&quot;So I spake, and quickly they hearkened to my words. But of Scylla</span><br><span class="line">I told them nothing more, a bane none might deal with, lest haply</span><br><span class="line">my company should cease from rowing for fear, and hide them in the</span><br><span class="line">hold. In that same hour I suffered myself to forget the hard</span><br><span class="line">behest of Circe, in that she bade me in nowise be armed; but I did</span><br><span class="line">on my glorious harness and caught up two long lances in my hands,</span><br><span class="line">and went on the decking of the prow, for thence methought that</span><br><span class="line">Scylla of the rock would first be seen, who was to bring woe on my</span><br><span class="line">company. Yet could I not spy her anywhere, and my eyes waxed weary</span><br><span class="line">for gazing all about toward the darkness of the rock.&quot;</span><br></pre></td></tr></table></figure>
<p>We have the sequence of bigrams:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">so i</span><br><span class="line">i spake</span><br><span class="line">spake and</span><br><span class="line">and quickly</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>And we have the sequence of trigrams:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">so i spake</span><br><span class="line">i spake and</span><br><span class="line">spake and quickly</span><br><span class="line">and quickly they</span><br><span class="line">quickly they hearkened</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Among the bigrams we see that several start with “<em>to</em>“, namely</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">to my</span><br><span class="line">to bring</span><br><span class="line">to forget</span><br></pre></td></tr></table></figure>
<p>And among the trigrams we see that two start with the bigram “<em>on my</em>“</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">on my glorious</span><br><span class="line">on my company</span><br></pre></td></tr></table></figure>

<p>We could say that the word “<em>to</em>“ has three <em>followers</em> in that excerpt: “<em>my</em>“, “<em>bring</em>“, and “<em>forget</em>“. We could also say that the bigram “<em>on my</em>“ has two followers “<em>glorious</em>“ and “<em>company</em>“.</p>
<p>If we examine a much larger text, then we can get a much richer collection of bigrams and trigrams. Furthermore, there will be a wealth of followers of words and bigrams.</p>
<p>Write the code for <code>chats.py</code>, a program that processes lines of text and builds a dictionary of bigram and trigram patterns it sees in that text. More specifically, each entry in that dictionary has as its search key either a word (like “<em>to</em>“) or a bigram (like “<em>on my</em>“). And then each key’s associated value is a <em>collection</em> of its followers. So, processing the text in the file <code>odyssey.txt</code> included in this folder, we’d get a dictionary that included these entries:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">to: the, Erebus, her, Scylla&#x27;s, mourn, my, forget, bring, ...</span><br><span class="line">on my: company, men</span><br></pre></td></tr></table></figure>

<p>In processing the text in this way, you should also pay attention to the stoppers. These are the punctuation marks “.”, “?”, and “!” that end English sentences and get treated as words by our code. Words that follow stoppers can be seen as possible starts to sentences.</p>
<p>When you process the text to register its bigrams and trigrams, we consider stoppers as participants in a bigram or trigram. This means, for example, that we will keep track of all words that follow a period mark “.” as a bigram entry. So, looking up “.” in our bigram&#x2F;trigram mdictionary of <code>odyssey.txt</code>, we have the entry</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.: for, and, not, her, up, thereby, verily, up, but, ...</span><br></pre></td></tr></table></figure>

<p>because these are the first words of all sentences following a period in that file. We furthermore, artificially treat the first line in any text as having followed a sentence ending with a period.  A file that starts with “<em>Lady Circe spoke unto me…</em>“ will instead have the dictionary entry</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.: lady, for, and, not, her, up, thereby, verily, up, but, ...</span><br></pre></td></tr></table></figure>

<p>We’d also see that, when “and” startsa sentence, that it is followed by several words. We have the trigram entry</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">. and: in, therein, thereon, looking, there, the, </span><br></pre></td></tr></table></figure>

<p>Once this dictionary of word followers and bigram followers is built, we now have a way of generating semi-gibberish! I’ll call this gibberish a <em>chat.</em></p>
<p>To start a chat, we pick a random word that’s a follower of “.” in our dictionary. Maybe that’s “<em>and</em>“. To pick the next word, we look up the bigram “<em>. and</em>“ in our dictionary, and pick one of its random followers. Maybe we choose “<em>in</em>“. And so then we work with the bigram “<em>and in</em>“ and see that it has the follower “<em>the</em>“. Continuing we see that “<em>in the</em>“ has a bunch of followers, so we pick one at random.  And so forth. This process might then give us this paragraph:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">and in the dread death struggle. as often as she belched it</span><br><span class="line">forth and thrice a day she sucks the water for thrice a day</span><br><span class="line">she sucks the water for thrice a day she sucks the water for</span><br><span class="line">thrice a day she sucks the water for thrice a day she sucks</span><br><span class="line">the water for thrice a day she sucks it down in terrible</span><br><span class="line">wise sucked down the salt sea water within she was all plain</span><br><span class="line">to see through her troubled deeps and overhead the spray</span><br><span class="line">fell on the decking of the sea. for on the other part are</span><br><span class="line">two rocks whereof the deep voiced amphitrite feeds countless</span><br><span class="line">flocks. not with an arrow across. but that other cliff</span><br><span class="line">odysseus thou shalt note lying lower hard by the first thou</span><br><span class="line">couldest send an arrow from a bow might a man whom she hath</span><br><span class="line">snatched from out the paths of the prow for thence methought</span><br><span class="line">that scylla of the cliff. yet could i not spy her anywhere</span><br><span class="line">and my eyes waxed weary for gazing all about toward the</span><br><span class="line">darkness of the rock for dolphins or sea dogs or whatso</span><br><span class="line">greater beast she may anywhere take whereof the one hand lay</span><br><span class="line">scylla and on the other part are two rocks whereof the one</span><br><span class="line">reaches with sharp peak to the wide heaven and a dark cloud</span><br><span class="line">encompasses it this never streams away and there is no clear</span><br><span class="line">air about the peak neither in summer nor in harvest tide.</span><br></pre></td></tr></table></figure>
<p>It’s not great, but it almost reads as something poignant!</p>
<p>Applying the same technique to a longer text, things may get <em>a little</em> better because the process has been trained on more data. Here’s a random result that comes from training such a process with <code>hundred_years.txt</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">aureliano segundo saw the starting point of her dense and</span><br><span class="line">prolonged silences that had turned him on the edge of town</span><br><span class="line">the pleasure of seeing us weep. somebody is coming he told</span><br><span class="line">him that for the first roll of sweaty papers from under the</span><br><span class="line">friendly eye of ursula&#x27;s knowing it or thinking about</span><br><span class="line">mauricio babilonia under the dark shapes of the anxious</span><br><span class="line">efforts of his hand. a broken down yellow train and that his</span><br><span class="line">wife who was not the impossibility of finding anyone to</span><br><span class="line">guess distances in the usual gothic letters to her that</span><br><span class="line">aureliano mentioned the matter was put under the mosquito</span><br><span class="line">netting that sleepwalker whom she could not succeed however</span><br><span class="line">in incorporating fernanda into the abyss of greatness. it</span><br><span class="line">was stuck to the heroism of his withdrawn self and made the</span><br><span class="line">earth i&#x27;ll convince you. then he came back from traveling</span><br><span class="line">around the room. suddenly during the months that at that</span><br><span class="line">time also stumbled and had been carried off to pray. colonel</span><br><span class="line">roque carnicero which meant butcher. was all he could wait</span><br><span class="line">as long as they got their peso and twenty five cents. they</span><br><span class="line">were rebeca s name bringing back the acidity of the latter</span><br><span class="line">elicited the whole group tried to cure with the saints will</span><br><span class="line">let me undergo the indignity of dying in the only thing that</span><br><span class="line">she will produce milk and biscuits and would bathe him bit</span><br><span class="line">by bit as he faced the firing squad could be heard</span><br><span class="line">chattering and singing at the door.</span><br></pre></td></tr></table></figure>

<p>In any case, write the code that processes a text and generates a chat using this random following word process. I’ve provided only a skeleton of that script within the starter code <code>chats.py</code>. That code reads in the text, line by line, and creates a word and stopper list of strings, just as we did for Part 1. Your job is to complete this code. It relies on you writing two functions <code>train</code> and <code>chat</code> as described below. The function <code>train</code> builds a digest of a text, summarizing what words tend to follow each bigram that occurs in the text.</p>
<p>Below we describe two different versions of <code>chats.py</code>.  The first version does not pay attention to the frequency of followers, and so makes a less accurate digest of the text. The second versions include follower frequency information in the digest, allowing a more statistically accurate generation of chatted text. This requires a slightly more sophisticated way of making a random word choice.  We detail all this below.</p>
<p>The second version is a bit more of a challenge and is a <strong>BONUS version</strong> of the assignment. Should you choose to write the second version, I encourage you to get the required first version working first.</p>
<h2 id="Coding-chats-py"><a href="#Coding-chats-py" class="headerlink" title="Coding chats.py"></a>Coding <code>chats.py</code></h2><p>Below I describe the two functions you need to write to complete Part 2, a function <code>train</code> that processes a text and a function <code>chat</code> that generates text from that training. Unlike Part 1, I don’t prescribe a bunch of smaller helper functions for you to write that get those two functions written. Nevertheless, I strongly encourage you to write the code in the form of several short functions that serve <code>train</code> and <code>chat</code>. I’m just giving you the chance to determine on your own what those helper functions should be.</p>
<h2 id="Write-train"><a href="#Write-train" class="headerlink" title="Write train"></a>Write <code>train</code></h2><p>Write the function <code>def train(wordList)</code> this is the Part 2 equivalent of the first part’s <code>wordFrequencies</code> function. It takes the list of words and stoppers in the text, as a list of strings. It should return a dictionary whose keys are either single words or bigrams. Each entry should represent all possible bigrams that start with that single word or all possible trigrams that start with that bigram. The data associated with each key in the dictionary should be that word’s&#x2F;bigram’s list of follower words. In the case of a bigram key, the string is just two words separated by a space.</p>
<p>In the above description, we consider stopper punctuation marks as keys or as parts of a bigram. The first word in the text should be considered a follower of all the stoppers. If the last word in the list is not a stopper, then it should have an entry with “.” as one of its followers.</p>
<p>If the text was something like “Hello, I must be going. Goodbye. Well hello again!” then the dictionary would have these listed entries:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&#x27;.&#x27;: [&#x27;hello&#x27;, &#x27;goodbye&#x27;, &#x27;well&#x27;],</span><br><span class="line">&#x27;!&#x27;: [&#x27;hello&#x27;],</span><br><span class="line">&#x27;?&#x27;: [&#x27;hello&#x27;],</span><br><span class="line">&#x27;hello&#x27;:[&#x27;i&#x27;, &#x27;again&#x27;],</span><br><span class="line">&#x27;i&#x27;:[&#x27;must&#x27;],</span><br><span class="line">&#x27;must&#x27;:[&#x27;be&#x27;],</span><br><span class="line">&#x27;be&#x27;:[&#x27;going&#x27;],</span><br><span class="line">&#x27;going&#x27;:[&#x27;.&#x27;],</span><br><span class="line">&#x27;goodbye&#x27;:[&#x27;.&#x27;],</span><br><span class="line">&#x27;well&#x27;:[&#x27;hello&#x27;],</span><br><span class="line">&#x27;again&#x27;:[&#x27;!&#x27;],</span><br><span class="line">&#x27;hello i&#x27;:[&#x27;must&#x27;],</span><br><span class="line">&#x27;i must&#x27;:[&#x27;be&#x27;],</span><br><span class="line">&#x27;must be&#x27;:[&#x27;going&#x27;],</span><br><span class="line">&#x27;be going&#x27;:[&#x27;.&#x27;],</span><br><span class="line">&#x27;. goodbye&#x27;:[&#x27;.&#x27;],</span><br><span class="line">&#x27;. well&#x27;:[&#x27;hello&#x27;],</span><br><span class="line">&#x27;well hello&#x27;:[&#x27;again&#x27;],</span><br><span class="line">&#x27;hello again&#x27;:[&#x27;!&#x27;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Note that the first 11 of these entries are “word followers”, describing bigrams in the text. The remaining entries are “bigram followers”, describing trigrams that occur in the text.  Note that there is no bigram entry for <code>again !</code>.</p>
<h2 id="Write-chat"><a href="#Write-chat" class="headerlink" title="Write chat"></a>Write <code>chat</code></h2><p>Write a procedure <code>def chat(biTriDict,lineWidth,numLines)</code> that takes the bigram&#x2F;trigram dictionary <code>biTriDict</code> as produced by <code>trainChat</code> along with some paramters for formatting the chatted text. The procedure should perform the random process described above to generate a random text (or “chat”) based on the training data.</p>
<p>To start a random chat, it should pick a random follower from the word entry for “.”. And then it should try to pick a follower from the bigram entry for “.” and that word. This leads to the first two words of the chat. Generating the next words continues in this way, by keeping track of the last two words that were generated. In summary:</p>
<ul>
<li>If the last two words are <code>w1</code> and <code>w2</code> (where either could be a stopper), pick a random follower from the list associated with that bigram. This would involve looking up the key <code>w1 + &quot; &quot; + w2</code> in the dictionary, and choosing a random word from that list.</li>
<li>If there is no entry for that bigram, or only one word was generated so far, pick a random follower from the list associated with the last word that was just generated.</li>
<li>If there is no entry for the last word, or if no words have been generated yet, pick a random follower from the list associated with the stopper “.”</li>
</ul>
<p>To generate a random choice, we’ve imported Python’s <code>random</code> package at the top of the file. You can have Python pick a random list element with <code>random.choice</code> like so:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; random.choice([&#x27;the&#x27;,&#x27;choice&#x27;,&#x27;is&#x27;,clear&#x27;])</span><br><span class="line">&#x27;is&#x27;</span><br></pre></td></tr></table></figure>

<p>The other two parameters <code>lineWidth</code> and <code>numLines</code> should be used to format the output of the chat. If the total number of characters (including spaces) generated on the current line of text of the chat has just exceeded <code>lineWidth</code>, then the next chatted word should appear on the next line. If we generate a stopper and the total number of lines with output so far with the chat has exceeded <code>numLines</code>, then we stop the chat generation process.</p>
<h1 id="BONUS-train-better-to-chat-better"><a href="#BONUS-train-better-to-chat-better" class="headerlink" title="BONUS: train better to chat better"></a>BONUS: train better to chat better</h1><p>The above functionality doesn’t quite give us what we want. It treats all followers as having equal possibility in the random text generation.  If there is a typical follower word of a bigram, one that appears a 100 times, and there is a rare follower of that same bigram, maybe occurring once, both are given equal weight by using <code>random.choice</code>.</p>
<p>To make this a little more concrete, suppose we processed the text of a large novel about a boy who runs, and runs well, but faces some struggles in becoming a good runner. Maybe he runs a bunch of races and, in one race he falls and gets hurt. He is so devastated that he quits the race and cries terribly over it. But the struggle is real, he rethinks his approach to running, overcomes some issues, and then just gets better and better.</p>
<p>Digesting this story with <code>train</code>, maybe the entry for the bigram <code>the boy</code> would be something like</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;the boy&#x27;:[&#x27;ran&#x27;,&#x27;fell&#x27;,&#x27;won&#x27;,&#x27;wept&#x27;,&#x27;ate&#x27;,&#x27;lost&#x27;, ...]</span><br></pre></td></tr></table></figure>

<p>But maybe he ran a lot, won a lot, and just fell and wept once.  The generated chat might then tell a tale of a voracious, despondent, clumsy running boy. This is because “wept” and “fell” would be just as likely as “ran” and “won”. This is interesting, maybe, but for certain texts this might lead top some haywire sentences becoming all too common.</p>
<p>Let’s enhance our dictionary to mimic the information we kept in Part 1 for the list of followers. Let’s have each possible following word <strong>keep a count</strong> of how many times it followed a word or a bigram.  Rather than having an entry tell us a list of followers, let’s instead have it be a list of each word along with a count.</p>
<p>If the trigram “the boy ran” appears 100 times, “the boy won” appeared 12 times, “the boy fell” twice, and “the boy wept” only once, then we want the entry to be like this</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;the boy&#x27;:[[&#x27;ran&#x27;,100],[&#x27;fell&#x27;,2],[&#x27;won&#x27;,12],[&#x27;wept&#x27;,1], ...]</span><br></pre></td></tr></table></figure>
<p>This digest has better information about the structure of the text.</p>
<h2 id="Write-trainBetter"><a href="#Write-trainBetter" class="headerlink" title="Write trainBetter"></a>Write <code>trainBetter</code></h2><p>Write a function <code>def trainBetter(wordList)</code> that builds and returns this improved dictionary. Change the main <code>chats,py</code> script to use it instead.</p>
<h2 id="Write-chatBetter"><a href="#Write-chatBetter" class="headerlink" title="Write chatBetter"></a>Write <code>chatBetter</code></h2><p>With this better text digest, we can probably now generate better random chats. Write a function <code>def chatBetter(biTriDict,lineWidth,numLines)</code> that assumes that <code>biTriDict</code> was built using <code>trainBetter</code>. The key change is that the call to choose the next word, something like</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nextWord = random.choice(biTriDict[w1 + &quot; &quot; + w2])</span><br></pre></td></tr></table></figure>

<p>needs to be changed to work with this frequency information.  Suppose that <code>w1</code> is <code>&quot;the&quot;</code> and <code>w2</code> is <code>&quot;boy&quot;</code>, and the entry for <code>&quot;the boy&quot;</code> is this info:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;the boy&#x27;:[[&#x27;ran&#x27;,100],[&#x27;fell&#x27;,2],[&#x27;won&#x27;,12],[&#x27;wept&#x27;,1]]</span><br></pre></td></tr></table></figure>

<p>Then, to choose a next word in a way that respects these frequencies we pick a random integer from 1 to 115. This can be done in Python with</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = random.randint(1,115)</span><br><span class="line">print(r)     # Outputs some number from 1 to 115.</span><br></pre></td></tr></table></figure>

<p>If the random number chosen is one of 1..100, then we output “ran”. If it’s 101 or 102, then we output “fell”. If one of 103..114, then we output “won”. And, finally, if the random number Python chooses is 105, we output “wept”.</p>
<p>Once you’ve figured this out, Change the main <code>chats,py</code> script to use <code>chatBetter</code> instead.</p>
<h1 id="What-to-hand-in"><a href="#What-to-hand-in" class="headerlink" title="What to hand in"></a>What to hand in</h1><p>On Gradescope, there will be two problems named <code>[PJ2] stats</code> and <code>[PJ2] chats</code> where you can upload <code>stats.py</code> and <code>chats.py</code>, respectively. These will not be autograded, but we will use them to inspect and give feedback on your work.</p>
<p>In addition to submitting the code, I’d like you to <strong>include sample output</strong> for each of the sample <code>.txt</code> files included in this folder.  You can do that in a terminal by using <em>output redirection</em> but with the character <code>&gt;</code>. This is similar to input redirection with <code>&lt;</code>. If, for example, you type</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 stats.py &lt; sonnets.txt &gt; sonnets_stats.txt</span><br></pre></td></tr></table></figure>

<p>then you will get a file named <code>sonnets_stats.txt</code> that has the statistics generated by the run of <code>stats.py</code> on the file <code>sonnets.txt</code>. If instead you type</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 chats.py &lt; sonnets.txt &gt; sonnets_chats.txt</span><br></pre></td></tr></table></figure>

<p>then you will get a file of the random chat output by your <code>chats.py</code> program, and trained on the file <code>sonnets.txt</code>.</p>
<p>Gradescope will allow you to upload all these <code>.txt</code> files with your <code>.py</code> file.</p>
<p>If, also, you want to tell us a bit more about your work, and document any other files, quirks, problems, or output of you program, you can include a file named <code>README.txt</code> that documents these aspects of your project. Include that same <code>README.txt</code> file with both the <code>stats.py</code> submission and the <code>chats.py</code> submission.</p>
<p>So, in total, you should</p>
<ul>
<li>submit <code>stats.py</code> and sample output files <code>.txt</code> for Part 1</li>
<li>submit <code>chats.py</code> and sample output files <code>.txt</code> for Part 2, and</li>
<li>(optionally) submit a text file named <code>README.txt</code>.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://nchanath.github.io/121-S23/2023/01/12/proj2/" data-id="cle4gt93j0013i9t0csz1f3jr" data-title="Project 2 -- Stats/Chats" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/121-S23/tags/Homework/" rel="tag">Homework</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/121-S23/2023/01/12/proj3/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Project 2 -- Hawks and Doves, simulating competition among birds
        
      </div>
    </a>
  
  
    <a href="/121-S23/2023/01/12/proj1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Project 1 -- The Game of Life and Image Processing</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/121-S23/tags/Announcements/" rel="tag">Announcements</a></li><li class="tag-list-item"><a class="tag-list-link" href="/121-S23/tags/Handouts/" rel="tag">Handouts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/121-S23/tags/Homework/" rel="tag">Homework</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/121-S23/tags/Announcements/" style="font-size: 10px;">Announcements</a> <a href="/121-S23/tags/Handouts/" style="font-size: 10px;">Handouts</a> <a href="/121-S23/tags/Homework/" style="font-size: 20px;">Homework</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/121-S23/archives/2023/01/">January 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/121-S23/2023/01/25/change-office-hours/">Change in office hours</a>
          </li>
        
          <li>
            <a href="/121-S23/2023/01/14/prog-ex-lec01-1/">Programming exercises for Lec01-1</a>
          </li>
        
          <li>
            <a href="/121-S23/2023/01/13/info/">Course information</a>
          </li>
        
          <li>
            <a href="/121-S23/2023/01/12/proj4/">Project 4 -- Adventure</a>
          </li>
        
          <li>
            <a href="/121-S23/2023/01/12/proj3/">Project 2 -- Hawks and Doves, simulating competition among birds</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Chanathip Namprempre<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/121-S23/tags/Announcements" class="mobile-nav-link">Announcements</a>
  
    <a href="/121-S23/syllabus" class="mobile-nav-link">Syllabus</a>
  
    <a href="/121-S23/lecturenotes" class="mobile-nav-link">Lecture Notes</a>
  
    <a href="/121-S23/tags/Handouts" class="mobile-nav-link">Handouts</a>
  
    <a href="/121-S23/tags/Homework" class="mobile-nav-link">Homework</a>
  
    <a href="/121-S23/resources" class="mobile-nav-link">Resources</a>
  
</nav>
    


<script src="/121-S23/js/jquery-3.4.1.min.js"></script>



  
<script src="/121-S23/fancybox/jquery.fancybox.min.js"></script>




<script src="/121-S23/js/script.js"></script>





  </div>
</body>
</html>